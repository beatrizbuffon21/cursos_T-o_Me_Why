# Machine Learning 

## Defini√ß√£o
O **aprendizado autom√°tico** √© um subcampo da Engenharia e da Ci√™ncia da Computa√ß√£o que evoluiu do estudo de reconhecimento de padr√µes e da teoria do aprendizado computacional em intelig√™ncia artificial. Em 1959, **Arthur Samuel** definiu aprendizado de m√°quina como o  
> "campo de estudo que d√° aos computadores a habilidade de aprender sem serem explicitamente programados".  

- [Fonte Britannica](https://www.britannica.com/technology/machine-learning)  
- [Livro de refer√™ncia](https://books.google.com.br/books?id=Dn-Gdoh66sgC&pg=PA89&redir_esc=y#v=onepage&q&f=false)  
- [Wikipedia - Aprendizado de m√°quina](https://pt.wikipedia.org/wiki/Aprendizado_de_m%C3%A1quina)  

---

## Intui√ß√£o com exemplo de frutas

Imagine que queremos adivinhar qual fruta uma pessoa vai comer.  

- Existem **7 frutas poss√≠veis** ‚Üí probabilidade inicial: `1/7`.  
- Recebemos dicas: *redonda, suculenta, vermelha, doce*.  
- O espa√ßo amostral √© reduzido para **2 frutas** ‚Üí probabilidade agora: `1/2`.  
- Exemplo: probabilidade de ser **banana** com essas dicas = `0`.  

Isso √© um exemplo de **probabilidade condicional**, onde o espa√ßo amostral vai sendo **restringido** conforme novas informa√ß√µes chegam.

---

## Representa√ß√£o em tabela

| Arredondada | Suculenta | Vermelha | Doce | Fruta    |
|-------------|-----------|----------|------|----------|
| 0           | 1         | 1        | 1    | Morango  |
| 1           | 0         | 0        | 0    | Lim√£o    |
| 1           | 1         | 0        | 1    | Pera     |
| 0           | 0         | 0        | 1    | Banana   |
| 1           | 1         | 1        | 1    | Cereja   |
| 1           | 1         | 1        | 0    | Tomate   |
| 1           | 1         | 1        | 1    | Ma√ß√£     |

- **Atributos (vari√°veis explicativas / independentes / covari√°veis):**  
  arredondada, suculenta, vermelha, doce  

- **Alvo (vari√°vel dependente / resposta):**  
  fruta  

Os **algoritmos de ML** descobrem regras com base nesses exemplos. Eles s√≥ "conhecem" os objetos/eventos apresentados e trabalham com probabilidades associadas.

---

## Exemplo com cervejas üç∫

- **Tipos de cerveja (alvo):**  
  - Pale Ale  
  - Weissbier  
  - Pilsen  

- **Atributos (vari√°veis preditoras):**  
  - Temperatura  
  - Tipo de copo  
  - Espuma  
  - Cor
    
### Algoritmo: √Årvore de Decis√£o 
- Funciona como uma sequ√™ncia de **ifs**, mas gerada automaticamente.  
- O algoritmo vai particionando os dados em "n√≥s" cada vez mais **puros** (ou seja, onde s√≥ resta um tipo de resposta).  
- Problema: se continuarmos dividindo at√© cada n√≥ ter apenas **uma amostra**, ca√≠mos em **overfitting** (o modelo aprende demais os exemplos e n√£o generaliza).  

---

## Observa√ß√µes importantes
- Nem todas as vari√°veis ajudam na classifica√ß√£o ‚Üí s√≥ descobrimos testando modelos.  
- Quanto mais vari√°veis, mais chances de algumas serem √∫teis.  
- Para vari√°veis categ√≥ricas, podemos usar **teste qui-quadrado** para verificar associa√ß√£o entre vari√°veis.

---

## Resumo
- Machine Learning = ensinar o computador a **aprender padr√µes** e tomar decis√µes com base em dados.  
- Trabalha de forma **probabil√≠stica**.  
- Usa **atributos (entradas)** ‚Üí para prever um **alvo (sa√≠da)**.  
- Risco de **overfitting** se o modelo aprender "demais".  
- Diferentes algoritmos existem para diferentes problemas (ex.: √°rvores de decis√£o, regress√µes, redes neurais, etc.).  
